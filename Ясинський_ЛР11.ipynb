{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyME7/NSJw7divaYJKmj4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PTIch06/YasynskyiLabs/blob/main/%D0%AF%D1%81%D0%B8%D0%BD%D1%81%D1%8C%D0%BA%D0%B8%D0%B9_%D0%9B%D0%A011.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Лабораторна робота №11\n",
        "##з дисципліни \"Технології обробки природомовної інформації\"\n",
        "###студента групи КН-31/2\n",
        "###Ясинського Дениса\n",
        "###Варіант №22"
      ],
      "metadata": {
        "id": "ZNuJDyXjvY0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import re\n",
        "import nltk.corpus\n",
        "\n",
        "from nltk import *\n",
        "from nltk.corpus import *\n",
        "from nltk import spearman_correlation\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "X7sNSIpIvbS_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer and see if you observe any differences.(провести нормалызацію двома способами, порівняти)"
      ],
      "metadata": {
        "id": "vuFIxPQfvmCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = 'Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word'\n",
        "\n",
        "print([PorterStemmer().stem(w) for w in word_tokenize(row)])\n",
        " \n",
        "print([LancasterStemmer().stem(w) for w in word_tokenize(row)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XGE0BFA58U8",
        "outputId": "1e1e78c4-7202-4522-b41e-d416c62f068f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['use', 'the', 'porter', 'stemmer', 'to', 'normal', 'some', 'token', 'text', ',', 'call', 'the', 'stemmer', 'on', 'each', 'word']\n",
            "['us', 'the', 'port', 'stem', 'to', 'norm', 'som', 'tok', 'text', ',', 'cal', 'the', 'stem', 'on', 'each', 'word']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ The index() function can be used to look up items in sequences. For example, 'inexpressible'.index('e') tells us the index of the first position of the letter e.<br>\n",
        "1) What happens when you look up a substring, e.g. 'inexpressible'.index('re')?<br>\n",
        "2) Define a variable words containing a list of words. Now use words.index() to look up the position of an individual word.<br>\n",
        "3) Define a variable silly as in the exercise above. Use the index() function in combination with list slicing to build a list phrase consisting of all the words up to (but not including) in in silly.<br>"
      ],
      "metadata": {
        "id": "_LAu9wJpvm6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'inexpressible'.index('re')\n",
        "#індекс букви"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Mgc8t79L6n",
        "outputId": "4209ae73-0336-47eb-8764-27fc48a72a08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = ['some', 'words', 'in', 'our', 'list']\n",
        "list.index('words')\n",
        "#індекс слова"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi3ixIM3-ZgO",
        "outputId": "482efdf5-d5c4-4235-892c-053dc8dc991e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = ['some', 'words', 'in', 'our', 'list']\n",
        "newList = list[:list.index('in')]\n",
        "print(newList)\n",
        "#видалити все включно"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhLmJMhs-Z2s",
        "outputId": "64ab55c2-8dfa-4c6e-a33a-e2e075e4f47c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['some', 'words']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Write code to convert nationality adjectives like Canadian and Australian to their corresponding nouns Canada and Australia (see http://en.wikipedia.org/wiki/List_of_adjectival_forms_of_place_names).(Перетворити національність на країну)"
      ],
      "metadata": {
        "id": "mbXAcMvx_rqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'African, European, American, Caribbean, Australian'\n",
        "pairs = [['ian', 'a'], ['can', 'ca'], ['n', ''], ['ea', ''], ['la', 'lia'], ['bb', 'bs']]\n",
        "               \n",
        "for pair in pairs:\n",
        "\tpattern = re.compile(r'(' + pair[0] + ')')\n",
        "\ttext = pattern.sub(pair[1], text)\n",
        " \n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsfWZK3AAB1T",
        "outputId": "13d7b53a-d7d1-4ef6-d76a-2039efe64a7f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Africa, Europ, America, Caribs, Australia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑Study the lolcat version of the book of Genesis, accessible as nltk.corpus.genesis.words('lolcat.txt'), and the rules for converting text into lolspeak athttp://www.lolcatbible.com/index.php?title=How_to_speak_lolcat. Define regular expressions to convert English words into corresponding lolspeak words."
      ],
      "metadata": {
        "id": "Swv3qoRMC90M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Проблеми з посиланням"
      ],
      "metadata": {
        "id": "8KY_e3zBJXFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "★ An interesting challenge for tokenization is words that have been split across a line-break. E.g. if long-term is split, then we have the string long-\\nterm.<br>\n",
        "1) Write a regular expression that identifies words that are hyphenated at a line-break. The expression will need to include the \\n character.<br>\n",
        "2) Use re.sub() to remove the \\n character from these words.<br>"
      ],
      "metadata": {
        "id": "W99JFLuSJu0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Знайти, де є перенос\n",
        "re.findall(r'\\w*-\\n\\w*', 'How about the text whi-\\nch we can show so-\\nme examples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0Iba6AKH5y",
        "outputId": "10869ed5-c70e-4df2-80af-d122fff28f5c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['whi-\\nch', 'so-\\nme']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 видалити перенос\n",
        "re.sub(r'-\\n', '', 'How about the text whi-\\nch we can show so-\\nme examples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Rl0uij0MAZG",
        "outputId": "d8aab397-84c2-470b-f86e-220e98776f13"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How about the text which we can show some examples'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "★ Obtain raw texts from two or more genres and compute their respective reading difficulty scores as in the earlier exercise on reading difficulty. E.g. compare ABC Rural News and ABC Science News (nltk.corpus.abc). Use Punkt to perform sentence segmentation."
      ],
      "metadata": {
        "id": "mKEmNS07KyXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sents = nltk.corpus.brown.sents()\n",
        "words = sum(len(s) for s in sents)\n",
        "chars = sum(len(s) for s in sents for w in s)\n",
        "muW = chars / words\n",
        "muS = words / len(sents)\n",
        "ari = 4.71 * muW + 0.5 * muS - 21.43\n",
        "\n",
        "print(ari)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-02Jb6AKzZC",
        "outputId": "fe84b35b-fa5f-44cc-e1bc-5fd8c138614e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124.03363109057847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "★ Rewrite the following nested loop as a nested list comprehension:"
      ],
      "metadata": {
        "id": "pEMU46YGNEXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['attribution', 'confabulation', 'elocution',\n",
        "         'sequoia', 'tenacious', 'unidirectional']\n",
        "vsequences = set()\n",
        "for word in words:\n",
        "  vowels = []\n",
        "  for char in word:\n",
        "    if char in 'aeiou':\n",
        "      vowels.append(char)\n",
        "      vsequences.add(''.join(vowels))\n",
        "sorted(vsequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j79mXg8NI_Y",
        "outputId": "921d7ab2-80da-43a3-e253-38b3bb70a6e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ai',\n",
              " 'aiu',\n",
              " 'aiui',\n",
              " 'aiuio',\n",
              " 'e',\n",
              " 'ea',\n",
              " 'eai',\n",
              " 'eaio',\n",
              " 'eaiou',\n",
              " 'eo',\n",
              " 'eou',\n",
              " 'eoui',\n",
              " 'eouio',\n",
              " 'eu',\n",
              " 'euo',\n",
              " 'euoi',\n",
              " 'euoia',\n",
              " 'o',\n",
              " 'oa',\n",
              " 'oau',\n",
              " 'oaua',\n",
              " 'oauai',\n",
              " 'oauaio',\n",
              " 'u',\n",
              " 'ui',\n",
              " 'uii',\n",
              " 'uiie',\n",
              " 'uiiei',\n",
              " 'uiieio',\n",
              " 'uiieioa']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['attribution', 'confabulation', 'elocution',\n",
        "         'sequoia', 'tenacious', 'unidirectional']\n",
        "vsequences = set()\n",
        "\n",
        "vsequences = sorted(set(''.join([i for i in word if i in 'aeiou']) for word in words))\n",
        "\n",
        "sorted(vsequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjuznaeJNjTa",
        "outputId": "4f101b4d-74a0-4383-ad10-0bc4f0f2c815"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Read the LanguageLog post on phrases of the form as best as p can and as best p can, where p is a pronoun. Investigate this phenomenon with the help of a corpus and the findall() method for searching tokenized text described in 3.5. http://itre.cis.upenn.edu/~myl/languagelog/archives/002733.html (Скористатися заміною)"
      ],
      "metadata": {
        "id": "3O8UnMI5UBAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r'as best as (?:I|you|we|they|he|she|it)', 'how to be as best as he is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZV1GaoyUSLz",
        "outputId": "3524e82e-137f-4b92-eead-85c8ee707c6c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['as best as he']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "★ Read the Wikipedia entry on Soundex. Implement this algorithm in Python."
      ],
      "metadata": {
        "id": "rInR1ZFSVnxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soundex(name):\n",
        "\n",
        "    soundexcoding = [' ', ' ', ' ', ' ']\n",
        "    soundexcodingindex = 1\n",
        "\n",
        "    mappings = \"01230120022455012623010202\"\n",
        "\n",
        "    soundexcoding[0] = name[0].upper()\n",
        "\n",
        "    for i in range(1, len(name)):\n",
        "\n",
        "         c = ord(name[i].upper()) - 65\n",
        "\n",
        "         if c >= 0 and c <= 25:\n",
        "\n",
        "             if mappings[c] != '0':\n",
        "\n",
        "                 if mappings[c] != soundexcoding[soundexcodingindex-1]:\n",
        "\n",
        "                     soundexcoding[soundexcodingindex] = mappings[c]\n",
        "                     soundexcodingindex += 1\n",
        "\n",
        "                 if soundexcodingindex > 3:\n",
        "\n",
        "                     break\n",
        "\n",
        "    if soundexcodingindex <= 3:\n",
        "        while(soundexcodingindex <= 3):\n",
        "            soundexcoding[soundexcodingindex] = '0'\n",
        "            soundexcodingindex += 1\n",
        "\n",
        "    return ''.join(soundexcoding)\n",
        "\n",
        "soundex('Denys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j2roPBiAVooN",
        "outputId": "818f7437-95e6-4781-ee3d-26a791523b38"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D520'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}