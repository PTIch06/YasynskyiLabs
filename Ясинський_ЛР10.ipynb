{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNGkRzyXvIEUXaUowCw8q+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PTIch06/YasynskyiLabs/blob/main/%D0%AF%D1%81%D0%B8%D0%BD%D1%81%D1%8C%D0%BA%D0%B8%D0%B9_%D0%9B%D0%A010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Лабораторна робота №10\n",
        "##з дисципліни \"Технології обробки природомовної інформації\"\n",
        "###студента групи КН-31/2\n",
        "###Ясинського Дениса\n",
        "###Варіант №22"
      ],
      "metadata": {
        "id": "z94uPoWH2zNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"book\")\n",
        "\n",
        "from nltk.book import *\n",
        "import re\n",
        "import random\n",
        "import urllib\n",
        "\n",
        "import nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c96nIw5n-aO8",
        "outputId": "600a9a1a-0071-4a1e-d768-a1b0d82ff8ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n",
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations. (Виправити текст)"
      ],
      "metadata": {
        "id": "Hbk1gB4B6V8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'colorless'\n",
        "s[:4]+'u'+s[4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HOg6nk5C3DqD",
        "outputId": "61d885fc-2455-4904-b51c-91079d740d32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'colourless'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat. (провести зріз по дефіс)"
      ],
      "metadata": {
        "id": "B63wcB486tYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'dish-es'\n",
        "s2 = 'run-ning'\n",
        "s3 = 'nation-ality'\n",
        "s4 = 'un-do'\n",
        "s5 = 'pre-heat'\n",
        "print(s1[:-3])\n",
        "print(s2[:-5])\n",
        "print(s3[:-6])\n",
        "print(s4[:-3])\n",
        "print(s5[:-5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw-i9vth60Ml",
        "outputId": "f8b7c5fb-ca7c-4f82-8b56-c1f8487a82b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dish\n",
            "run\n",
            "nation\n",
            "un\n",
            "pre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string? (Що буде, коли поставиму замалий індекс)"
      ],
      "metadata": {
        "id": "mQ3K7KsQ7em5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1[-9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "bHCl6tIs7iJH",
        "outputId": "1a5061ec-18ea-4ca2-a356-b15d5774f7fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b5708125b3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values. (Подивитися на роботу)"
      ],
      "metadata": {
        "id": "gpQNiV3970HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex = 'Something about python'\n",
        "print(ex[6:11:2])\n",
        "print(ex[10:5:-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acUfDgGL8DR-",
        "outputId": "6a95d7b4-d65e-4a33-da44-a12815ae1d51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iga\n",
            "agi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result.(Що буде?)"
      ],
      "metadata": {
        "id": "LxSY1f4n8wsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex = \"patato\"\n",
        "ex[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c0_u7WWP89DL",
        "outputId": "5b7fad86-2523-4970-8a85-7bd5411d8fef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'otatap'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ Describe the class of strings matched by the following regular expressions.(Пояснити результат маныпуляцій)"
      ],
      "metadata": {
        "id": "n9Zj0MP69VLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[a-zA-Z]+\n",
        "nltk.re_show('[a-zA-Z]+','Test string 123 456')\n",
        "print('всі слова довжиною від 1 символа')\n",
        "print()\n",
        "#[A-Z][a-z]*\n",
        "nltk.re_show('[A-Z][a-z]*','Test string 123 456')\n",
        "print('всі слова, які починаються з великої літери і мають довжину від 1 символа')\n",
        "print()\n",
        "#p[aeiou]{,2}t\n",
        "nltk.re_show('p[aeiou]{,2}t','Test string on port 123 456 by pit')\n",
        "print('слова, які починаються з p, закінчуються t, а в середині не більше двох однакових літер.')\n",
        "print()\n",
        "#\\d+(\\.\\d+)?\n",
        "nltk.re_show('\\d+(\\.\\d+)?','Test string on 123.456 port')\n",
        "print('числа, точка, знову числа')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiafeKFX9Z7T",
        "outputId": "a96cbb50-a906-469e-d724-5ffb8dc51b40"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Test} {string} 123 456\n",
            "всі слова довжиною від 1 символа\n",
            "\n",
            "{Test} string 123 456\n",
            "всі слова, які починаються з великої літери і мають довжину від 1 символа\n",
            "\n",
            "Test string on port 123 456 by {pit}\n",
            "слова, які починаються з p, закінчуються t, а в середині не більше двох однакових літер.\n",
            "\n",
            "Test string on {123.456} port\n",
            "числа, точка, знову числа\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ Write regular expressions to match the following classes of strings: (Написати регулярні вирази дляя класів)"
      ],
      "metadata": {
        "id": "xoK0eWbTF7Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A single determiner (assume that a, an, and the are the only determiners)\n",
        "#^(an?|the)$\n",
        "#An arithmetic expression using integers, addition, and multiplication, such as 2*3+8.\n",
        "# [\\d+*-/]+"
      ],
      "metadata": {
        "id": "y-9DBvaTF_gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "☼ Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL. (Дати урл, повернути урл без штмл)"
      ],
      "metadata": {
        "id": "pZerFfNhGtrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(urllib.request.urlopen('http://nltk.org/').read().decode('utf8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHpCGDpMGtF8",
        "outputId": "10f96181-4bf2-4541-b11a-8a419227c0cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\r\n",
            "<head>\r\n",
            "  <meta charset=\"utf-8\">\r\n",
            "  <meta name=\"generator\" content=\"Docutils 0.17: http://docutils.sourceforge.net/\" />\r\n",
            "\r\n",
            "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n",
            "  <meta name=\"theme-color\" content=\"#2D2D2D\" />\r\n",
            "  \r\n",
            "  <title>NLTK :: Natural Language Toolkit</title>\r\n",
            "  \r\n",
            "\r\n",
            "  <link rel=\"stylesheet\" href=\"_static/css/nltk_theme.css\"/>\r\n",
            "  <link rel=\"stylesheet\" href=\"_static/css/custom.css\"/>\r\n",
            "\r\n",
            "  <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"./\" src=\"_static/documentation_options.js\"></script>\r\n",
            "      <script type=\"text/javascript\" src=\"_static/documentation_options.js\"></script>\r\n",
            "      <script type=\"text/javascript\" src=\"_static/jquery.js\"></script>\r\n",
            "      <script type=\"text/javascript\" src=\"_static/underscore.js\"></script>\r\n",
            "      <script type=\"text/javascript\" src=\"_static/doctools.js\"></script>\r\n",
            "  \r\n",
            "\r\n",
            "  <script src=\"https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs\"></script> \r\n",
            "</head>\r\n",
            "\r\n",
            "<body>\r\n",
            "  <div id=\"nltk-theme-container\">\r\n",
            "    <header>\r\n",
            "      <div id=\"logo-container\">\r\n",
            "          \r\n",
            "          <h1>\r\n",
            "            <a href=\"#\">NLTK</a>\r\n",
            "          </h1>\r\n",
            "          \r\n",
            "      </div>\r\n",
            "      <div id=\"project-container\">\r\n",
            "        \r\n",
            "        <h1>Documentation</h1>\r\n",
            "        \r\n",
            "      </div>\r\n",
            "\r\n",
            "      <a id=\"menu-toggle\" class=\"fa fa-bars\" aria-hidden=\"true\"></a>\r\n",
            "\r\n",
            "      <script type=\"text/javascript\">\r\n",
            "        $(\"#menu-toggle\").click(function() {\r\n",
            "          $(\"#menu-toggle\").toggleClass(\"toggled\");\r\n",
            "          $(\"#side-menu-container\").slideToggle(300);\r\n",
            "        });\r\n",
            "      </script>\r\n",
            "    </header>\r\n",
            "\r\n",
            "    <div id=\"content-container\">\r\n",
            "\r\n",
            "      <div id=\"side-menu-container\">\r\n",
            "\r\n",
            "        <div id=\"search\" role=\"search\">\r\n",
            "        <form id=\"rtd-search-form\" class=\"wy-form\" action=\"search.html\" method=\"get\">\r\n",
            "            <input type=\"text\" name=\"q\" placeholder=\"Search\" />\r\n",
            "            <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\r\n",
            "            <input type=\"hidden\" name=\"area\" value=\"default\" />\r\n",
            "        </form>\r\n",
            "</div>\r\n",
            "\r\n",
            "        <div id=\"side-menu\" role=\"navigation\">\r\n",
            "          \r\n",
            "  \r\n",
            "    \r\n",
            "  \r\n",
            "  \r\n",
            "    <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">NLTK Documentation</span></p>\r\n",
            "<ul>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api/nltk.html\">API Reference</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"howto.html\">Example Usage</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"py-modindex.html\">Module Index</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki\">Wiki</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki/FAQ\">FAQ</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/issues\">Open Issues</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk\">NLTK on GitHub</a></li>\r\n",
            "</ul>\r\n",
            "<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Installation</span></p>\r\n",
            "<ul>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"install.html\">Installing NLTK</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"data.html\">Installing NLTK Data</a></li>\r\n",
            "</ul>\r\n",
            "<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">More</span></p>\r\n",
            "<ul>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"news.html\">Release Notes</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"contribute.html\">Contributing to NLTK</a></li>\r\n",
            "<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"team.html\">NLTK Team</a></li>\r\n",
            "</ul>\r\n",
            "\r\n",
            "  \r\n",
            "\r\n",
            "        </div>\r\n",
            "\r\n",
            "        \r\n",
            "      </div>\r\n",
            "\r\n",
            "      <div id=\"main-content-container\">\r\n",
            "        <div id=\"main-content\" role=\"main\">\r\n",
            "          \r\n",
            "  <section id=\"natural-language-toolkit\">\r\n",
            "<h1>Natural Language Toolkit<a class=\"headerlink\" href=\"#natural-language-toolkit\" title=\"Permalink to this headline\">¶</a></h1>\r\n",
            "<p>NLTK is a leading platform for building Python programs to work with human language data.\r\n",
            "It provides easy-to-use interfaces to <a class=\"reference external\" href=\"https://www.nltk.org/nltk_data/\">over 50 corpora and lexical\r\n",
            "resources</a> such as WordNet,\r\n",
            "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\r\n",
            "wrappers for industrial-strength NLP libraries,\r\n",
            "and an active <a class=\"reference external\" href=\"https://groups.google.com/group/nltk-users\">discussion forum</a>.</p>\r\n",
            "<p>Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\r\n",
            "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\r\n",
            "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.</p>\r\n",
            "<p>NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\r\n",
            "and “an amazing library to play with natural language.”</p>\r\n",
            "<p><a class=\"reference external\" href=\"https://www.nltk.org/book/\">Natural Language Processing with Python</a> provides a practical\r\n",
            "introduction to programming for language processing.\r\n",
            "Written by the creators of NLTK, it guides the reader through the fundamentals\r\n",
            "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\r\n",
            "and more.\r\n",
            "The online version of the book has been been updated for Python 3 and NLTK 3.\r\n",
            "(The original Python 2 version is still available at <a class=\"reference external\" href=\"https://www.nltk.org/book_1ed\">https://www.nltk.org/book_1ed</a>.)</p>\r\n",
            "<section id=\"some-simple-things-you-can-do-with-nltk\">\r\n",
            "<h2>Some simple things you can do with NLTK<a class=\"headerlink\" href=\"#some-simple-things-you-can-do-with-nltk\" title=\"Permalink to this headline\">¶</a></h2>\r\n",
            "<p>Tokenize and tag some text:</p>\r\n",
            "<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">nltk</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sentence</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;&quot;&quot;At eight o&#39;clock on Thursday morning</span>\r\n",
            "<span class=\"gp\">... </span><span class=\"s2\">Arthur didn&#39;t feel very good.&quot;&quot;&quot;</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">word_tokenize</span><span class=\"p\">(</span><span class=\"n\">sentence</span><span class=\"p\">)</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tokens</span>\r\n",
            "<span class=\"go\">[&#39;At&#39;, &#39;eight&#39;, &quot;o&#39;clock&quot;, &#39;on&#39;, &#39;Thursday&#39;, &#39;morning&#39;,</span>\r\n",
            "<span class=\"go\">&#39;Arthur&#39;, &#39;did&#39;, &quot;n&#39;t&quot;, &#39;feel&#39;, &#39;very&#39;, &#39;good&#39;, &#39;.&#39;]</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tagged</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">pos_tag</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tagged</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span>\r\n",
            "<span class=\"go\">[(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;), (&#39;on&#39;, &#39;IN&#39;),</span>\r\n",
            "<span class=\"go\">(&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;)]</span>\r\n",
            "</pre></div>\r\n",
            "</div>\r\n",
            "<p>Identify named entities:</p>\r\n",
            "<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">entities</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">chunk</span><span class=\"o\">.</span><span class=\"n\">ne_chunk</span><span class=\"p\">(</span><span class=\"n\">tagged</span><span class=\"p\">)</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">entities</span>\r\n",
            "<span class=\"go\">Tree(&#39;S&#39;, [(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;),</span>\r\n",
            "<span class=\"go\">           (&#39;on&#39;, &#39;IN&#39;), (&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;),</span>\r\n",
            "<span class=\"go\">       Tree(&#39;PERSON&#39;, [(&#39;Arthur&#39;, &#39;NNP&#39;)]),</span>\r\n",
            "<span class=\"go\">           (&#39;did&#39;, &#39;VBD&#39;), (&quot;n&#39;t&quot;, &#39;RB&#39;), (&#39;feel&#39;, &#39;VB&#39;),</span>\r\n",
            "<span class=\"go\">           (&#39;very&#39;, &#39;RB&#39;), (&#39;good&#39;, &#39;JJ&#39;), (&#39;.&#39;, &#39;.&#39;)])</span>\r\n",
            "</pre></div>\r\n",
            "</div>\r\n",
            "<p>Display a parse tree:</p>\r\n",
            "<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">nltk.corpus</span> <span class=\"kn\">import</span> <span class=\"n\">treebank</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">treebank</span><span class=\"o\">.</span><span class=\"n\">parsed_sents</span><span class=\"p\">(</span><span class=\"s1\">&#39;wsj_0001.mrg&#39;</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\r\n",
            "<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\r\n",
            "</pre></div>\r\n",
            "</div>\r\n",
            "<img alt=\"_images/tree.gif\" src=\"_images/tree.gif\" />\r\n",
            "<p>NB. If you publish work that uses NLTK, please cite the NLTK book as\r\n",
            "follows:</p>\r\n",
            "<blockquote>\r\n",
            "<div><p>Bird, Steven, Edward Loper and Ewan Klein (2009), <em>Natural Language Processing with Python</em>.  O’Reilly Media Inc.</p>\r\n",
            "</div></blockquote>\r\n",
            "</section>\r\n",
            "<section id=\"next-steps\">\r\n",
            "<h2>Next Steps<a class=\"headerlink\" href=\"#next-steps\" title=\"Permalink to this headline\">¶</a></h2>\r\n",
            "<ul class=\"simple\">\r\n",
            "<li><p><a class=\"reference external\" href=\"https://groups.google.com/group/nltk\">Sign up for release announcements</a></p></li>\r\n",
            "<li><p><a class=\"reference external\" href=\"https://groups.google.com/group/nltk-users\">Join in the discussion</a></p></li>\r\n",
            "</ul>\r\n",
            "<div class=\"toctree-wrapper compound\">\r\n",
            "</div>\r\n",
            "<div class=\"toctree-wrapper compound\">\r\n",
            "</div>\r\n",
            "<div class=\"toctree-wrapper compound\">\r\n",
            "</div>\r\n",
            "</section>\r\n",
            "</section>\r\n",
            "\r\n",
            "\r\n",
            "        </div>\r\n",
            "      </div>\r\n",
            "\r\n",
            "    </div>\r\n",
            "\r\n",
            "<footer>\r\n",
            "    <div id=\"footer-info\">\r\n",
            "        <ul id=\"build-details\">\r\n",
            "            \r\n",
            "                <li class=\"footer-element\">\r\n",
            "                    \r\n",
            "                        <a href=\"_sources/index.rst.txt\" rel=\"nofollow\"> source</a>\r\n",
            "                    \r\n",
            "                </li>\r\n",
            "            \r\n",
            "\r\n",
            "            \r\n",
            "                <li class=\"footer-element\">\r\n",
            "                    <a href=\"https://github.com/nltk/nltk/tree/3.7\">3.7</a>\r\n",
            "                </li>\r\n",
            "            \r\n",
            "\r\n",
            "            \r\n",
            "                <li class=\"footer-element\">\r\n",
            "                    Mar 25, 2022\r\n",
            "                </li>\r\n",
            "            \r\n",
            "        </ul>\r\n",
            "\r\n",
            "        \r\n",
            "            <div id=\"copyright\">\r\n",
            "                &copy; 2022, NLTK Project\r\n",
            "            </div>\r\n",
            "        \r\n",
            "\r\n",
            "        <div id=\"credit\">\r\n",
            "            created with <a href=\"http://sphinx-doc.org/\">Sphinx</a> and <a href=\"https://github.com/tomaarsen/nltk_theme\">NLTK Theme</a>\r\n",
            "        </div>\r\n",
            "    </div>\r\n",
            "</footer> \r\n",
            "\r\n",
            "</div>\r\n",
            "\r\n",
            "</body>\r\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Read in some text from a corpus, tokenize it, and print the list of all wh-word types that occur. (wh-words in English are used in questions, relative clauses and exclamations: who, which, what, and so on.) Print them in order. Are any words duplicated in this list, because of the presence of case distinctions or punctuation?(Знайти питальні слова)"
      ],
      "metadata": {
        "id": "-7nhPHqjJuT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(set([word for word in text5 if word.startswith('wh')]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CWmc-gJJv01",
        "outputId": "bdafaa48-f1b1-4733-a42e-1e5d1320b3d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'when', 'who', 'whered', 'whoa', 'where', 'wher', 'whoo', 'white', 'whud', 'whuuped', 'whoever', 'whilst', 'whisper', 'whoopZ', 'whispers', 'whjat', 'whupped', 'whhhooooo', 'whose', 'wheres', 'whou', 'whew', 'whys', 'whiteys', 'wheels', 'whatever', 'whitte', 'whos', 'whisling', 'whisperer', 'whenever', 'whistles', 'while', 'whether', 'whatca', 'what', 'whereabouts', 'whooo', 'whole', 'which', 'whatcha', 'whip', 'wha', 'wheeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', 'why', 'whore', 'whats', 'whiskey', 'wheel', 'whewwwwww', 'whaaaaats', 'whispering', 'whipped', 'whoaaaaaaaaaaaa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Write a function unknown() that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using re.findall()) and remove any items from this set that occur in the Words Corpus (nltk.corpus.words). Try to categorize these words manually and discuss your findings.(Взяти текст з веб-сторінки)"
      ],
      "metadata": {
        "id": "bbLoIorPa8gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page = urllib.request.urlopen('http://nltk.org/').read().decode('utf8')\n",
        "set(re.split(r'[\\W]+', page.lower())) - set(nltk.corpus.words.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ZBU9F5a82D",
        "outputId": "fa902195-0c10-45ea-8a97-d2a46a375897"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'',\n",
              " '0',\n",
              " '1',\n",
              " '17',\n",
              " '2',\n",
              " '2009',\n",
              " '2022',\n",
              " '25',\n",
              " '2d2d2d',\n",
              " '3',\n",
              " '300',\n",
              " '39',\n",
              " '3jsmqc5zeqfe8dkxoy1kkmuoi3acfkrjpsw2aap7ontyiaxi6i7xpjvwyevfcq550os3jlrgsnolgbday6s0pbk2tfnjebsfq31lb0onx407pja5v2faradwsw63mn5kulyr9j2tgx3zecanl',\n",
              " '50',\n",
              " '55r_',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '_images',\n",
              " '_sources',\n",
              " '_static',\n",
              " 'a',\n",
              " 'action',\n",
              " 'active',\n",
              " 'alike',\n",
              " 'all',\n",
              " 'along',\n",
              " 'alongside',\n",
              " 'alt',\n",
              " 'amazing',\n",
              " 'an',\n",
              " 'analyzing',\n",
              " 'and',\n",
              " 'announcements',\n",
              " 'api',\n",
              " 'area',\n",
              " 'aria',\n",
              " 'arthur',\n",
              " 'as',\n",
              " 'at',\n",
              " 'available',\n",
              " 'bars',\n",
              " 'been',\n",
              " 'best',\n",
              " 'bird',\n",
              " 'blockquote',\n",
              " 'body',\n",
              " 'book',\n",
              " 'book_1ed',\n",
              " 'build',\n",
              " 'building',\n",
              " 'by',\n",
              " 'c',\n",
              " 'called',\n",
              " 'can',\n",
              " 'caption',\n",
              " 'categorizing',\n",
              " 'cd',\n",
              " 'charset',\n",
              " 'check_keywords',\n",
              " 'chunk',\n",
              " 'cite',\n",
              " 'class',\n",
              " 'classification',\n",
              " 'click',\n",
              " 'clock',\n",
              " 'color',\n",
              " 'com',\n",
              " 'community',\n",
              " 'compound',\n",
              " 'comprehensive',\n",
              " 'computational',\n",
              " 'container',\n",
              " 'content',\n",
              " 'contribute',\n",
              " 'contributing',\n",
              " 'copy',\n",
              " 'copyright',\n",
              " 'corpora',\n",
              " 'corpus',\n",
              " 'created',\n",
              " 'creators',\n",
              " 'credit',\n",
              " 'css',\n",
              " 'custom',\n",
              " 'data',\n",
              " 'default',\n",
              " 'details',\n",
              " 'device',\n",
              " 'did',\n",
              " 'didn',\n",
              " 'discussion',\n",
              " 'display',\n",
              " 'div',\n",
              " 'do',\n",
              " 'doc',\n",
              " 'doctest',\n",
              " 'doctools',\n",
              " 'doctype',\n",
              " 'documentation',\n",
              " 'documentation_options',\n",
              " 'docutils',\n",
              " 'draw',\n",
              " 'driven',\n",
              " 'easy',\n",
              " 'educators',\n",
              " 'edward',\n",
              " 'eight',\n",
              " 'ejxnjueogyaqaf8jr7kw6wihdh7sp1cw2mgxgmn6',\n",
              " 'element',\n",
              " 'em',\n",
              " 'email',\n",
              " 'engineers',\n",
              " 'entities',\n",
              " 'ewan',\n",
              " 'example',\n",
              " 'external',\n",
              " 'fa',\n",
              " 'faq',\n",
              " 'feel',\n",
              " 'follows',\n",
              " 'footer',\n",
              " 'for',\n",
              " 'form',\n",
              " 'fortawesome',\n",
              " 'forum',\n",
              " 'free',\n",
              " 'from',\n",
              " 'function',\n",
              " 'fundamentals',\n",
              " 'generator',\n",
              " 'get',\n",
              " 'gif',\n",
              " 'github',\n",
              " 'go',\n",
              " 'good',\n",
              " 'google',\n",
              " 'gp',\n",
              " 'group',\n",
              " 'groups',\n",
              " 'gt',\n",
              " 'guide',\n",
              " 'guides',\n",
              " 'h1',\n",
              " 'h2',\n",
              " 'hands',\n",
              " 'has',\n",
              " 'head',\n",
              " 'header',\n",
              " 'headerlink',\n",
              " 'heading',\n",
              " 'headline',\n",
              " 'hidden',\n",
              " 'highlight',\n",
              " 'howto',\n",
              " 'href',\n",
              " 'html',\n",
              " 'http',\n",
              " 'https',\n",
              " 'human',\n",
              " 'id',\n",
              " 'identify',\n",
              " 'if',\n",
              " 'img',\n",
              " 'import',\n",
              " 'in',\n",
              " 'inc',\n",
              " 'index',\n",
              " 'industrial',\n",
              " 'industry',\n",
              " 'info',\n",
              " 'initial',\n",
              " 'input',\n",
              " 'install',\n",
              " 'installation',\n",
              " 'installing',\n",
              " 'interfaces',\n",
              " 'internal',\n",
              " 'introducing',\n",
              " 'introduction',\n",
              " 'is',\n",
              " 'issues',\n",
              " 'it',\n",
              " 'javascript',\n",
              " 'jj',\n",
              " 'jjps',\n",
              " 'join',\n",
              " 'jquery',\n",
              " 'js',\n",
              " 'klein',\n",
              " 'kn',\n",
              " 'l1',\n",
              " 'language',\n",
              " 'leading',\n",
              " 'lexical',\n",
              " 'li',\n",
              " 'libraries',\n",
              " 'library',\n",
              " 'linguistic',\n",
              " 'linguistics',\n",
              " 'linguists',\n",
              " 'link',\n",
              " 'linux',\n",
              " 'logo',\n",
              " 'loper',\n",
              " 'mac',\n",
              " 'main',\n",
              " 'mar',\n",
              " 'media',\n",
              " 'menu',\n",
              " 'meta',\n",
              " 'method',\n",
              " 'mi',\n",
              " 'modindex',\n",
              " 'module',\n",
              " 'more',\n",
              " 'morning',\n",
              " 'mrg',\n",
              " 'n',\n",
              " 'name',\n",
              " 'named',\n",
              " 'natural',\n",
              " 'navigation',\n",
              " 'nb',\n",
              " 'ne_chunk',\n",
              " 'net',\n",
              " 'news',\n",
              " 'next',\n",
              " 'nlp',\n",
              " 'nltk',\n",
              " 'nltk_data',\n",
              " 'nltk_theme',\n",
              " 'nn',\n",
              " 'nnp',\n",
              " 'nofollow',\n",
              " 'notes',\n",
              " 'notranslate',\n",
              " 'o',\n",
              " 'of',\n",
              " 'on',\n",
              " 'online',\n",
              " 'open',\n",
              " 'org',\n",
              " 'original',\n",
              " 'os',\n",
              " 'over',\n",
              " 'p',\n",
              " 'parse',\n",
              " 'parsed_sents',\n",
              " 'parsing',\n",
              " 'permalink',\n",
              " 'person',\n",
              " 'placeholder',\n",
              " 'platform',\n",
              " 'play',\n",
              " 'please',\n",
              " 'plus',\n",
              " 'pos_tag',\n",
              " 'practical',\n",
              " 'pre',\n",
              " 'processing',\n",
              " 'programming',\n",
              " 'programs',\n",
              " 'project',\n",
              " 'provides',\n",
              " 'publish',\n",
              " 'py',\n",
              " 'python',\n",
              " 'q',\n",
              " 'quot',\n",
              " 'rb',\n",
              " 'reader',\n",
              " 'reasoning',\n",
              " 'reference',\n",
              " 'reilly',\n",
              " 'rel',\n",
              " 'release',\n",
              " 'researchers',\n",
              " 'resources',\n",
              " 'role',\n",
              " 'rst',\n",
              " 'rtd',\n",
              " 's',\n",
              " 's1',\n",
              " 's2',\n",
              " 'scale',\n",
              " 'script',\n",
              " 'search',\n",
              " 'section',\n",
              " 'semantic',\n",
              " 'sentence',\n",
              " 'side',\n",
              " 'sign',\n",
              " 'simple',\n",
              " 'slidetoggle',\n",
              " 'some',\n",
              " 'source',\n",
              " 'sourceforge',\n",
              " 'span',\n",
              " 'sphinx',\n",
              " 'src',\n",
              " 'stemming',\n",
              " 'steps',\n",
              " 'steven',\n",
              " 'still',\n",
              " 'strength',\n",
              " 'structure',\n",
              " 'students',\n",
              " 'stylesheet',\n",
              " 'such',\n",
              " 'suitable',\n",
              " 'suite',\n",
              " 't',\n",
              " 'tag',\n",
              " 'tagged',\n",
              " 'tagging',\n",
              " 'teaching',\n",
              " 'team',\n",
              " 'text',\n",
              " 'thanks',\n",
              " 'that',\n",
              " 'the',\n",
              " 'theme',\n",
              " 'things',\n",
              " 'this',\n",
              " 'through',\n",
              " 'thursday',\n",
              " 'title',\n",
              " 'tl',\n",
              " 'to',\n",
              " 'toctree',\n",
              " 'toggle',\n",
              " 'toggleclass',\n",
              " 'toggled',\n",
              " 'tokenization',\n",
              " 'tokenize',\n",
              " 'tokens',\n",
              " 'tomaarsen',\n",
              " 'tool',\n",
              " 'toolkit',\n",
              " 'topics',\n",
              " 'tree',\n",
              " 'treebank',\n",
              " 'true',\n",
              " 'txt',\n",
              " 'type',\n",
              " 'ul',\n",
              " 'underscore',\n",
              " 'up',\n",
              " 'updated',\n",
              " 'url_root',\n",
              " 'usage',\n",
              " 'use',\n",
              " 'users',\n",
              " 'uses',\n",
              " 'using',\n",
              " 'utf',\n",
              " 'value',\n",
              " 'vb',\n",
              " 'vbd',\n",
              " 'version',\n",
              " 'very',\n",
              " 'viewport',\n",
              " 'width',\n",
              " 'wiki',\n",
              " 'windows',\n",
              " 'with',\n",
              " 'wonderful',\n",
              " 'word_tokenize',\n",
              " 'wordnet',\n",
              " 'work',\n",
              " 'working',\n",
              " 'wrapper',\n",
              " 'wrappers',\n",
              " 'writing',\n",
              " 'written',\n",
              " 'wsj_0001',\n",
              " 'www',\n",
              " 'wy',\n",
              " 'x',\n",
              " 'yes',\n",
              " 'you'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Are you able to write a regular expression to tokenize text in such a way that the word don't is tokenized into do and n't? Explain why this regular expression won't work: «n't|\\w+».(Виправити команду)"
      ],
      "metadata": {
        "id": "aCjleME1c0hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str = 'I don\\'t know'\n",
        "re.findall(r'\\b(do)(n\\'t)', str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YNGPlDLc7TF",
        "outputId": "62f6456d-22eb-47ac-be90-608a44f24f1d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('do', \"n't\")]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Python's random module includes a function choice() which randomly chooses an item from a sequence, e.g. choice(\"aehh \") will produce one of four possible characters, with the letter h being twice as frequent as the others. Write a generator expression that produces a sequence of 500 randomly chosen letters drawn from the string \"aehh \", and put this expression inside a call to the ''.join()function, to concatenate them into one long string. You should get a result that looks like uncontrolled sneezing or maniacal laughter: he  haha ee  heheeh eha. Use split() and join() again to normalize the whitespace in this string. (Згенерувати сміх)"
      ],
      "metadata": {
        "id": "0C7TXgK_efX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str = ''.join(random.choice('aehh ') for x in range(500))\n",
        "str1 = ' '.join(str.split())\n",
        "print(str)\n",
        "print()\n",
        "print(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUFcHCk4ewRw",
        "outputId": "b603e952-64c0-4316-cf33-83c267f66afe"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h  ha heheehhhheh hhae hehehaehh aeahhha hee h ha ee aeaa haheheahae  ah  aea heea hahahh   heheehhaehaeaheh h hheahaaaea hhahahahehha ea ha hheeheh h  a  ehaehe heheaahhahehhhha heh hehhhhhh hhhheahhah hh ahh   ha hheh  aah a eheeeeehhhahh  hhaahhh   eehah a ah ha  aaeeeaeh eeh aa  a  ahh  ae heh h haehhh hhheaa   eheah hhhhehehha   hea aeaah haheaa  he aehehhhhaa eh haeaahhhhh aaaeeahahh hah   aheaeeheheh e aha aaeeehe ea hhhaahaeha  eaeh h ee ahhehae aaahhhhahhaaa haaeee ea hehhhhhahh  hehhea\n",
            "\n",
            "h ha heheehhhheh hhae hehehaehh aeahhha hee h ha ee aeaa haheheahae ah aea heea hahahh heheehhaehaeaheh h hheahaaaea hhahahahehha ea ha hheeheh h a ehaehe heheaahhahehhhha heh hehhhhhh hhhheahhah hh ahh ha hheh aah a eheeeeehhhahh hhaahhh eehah a ah ha aaeeeaeh eeh aa a ahh ae heh h haehhh hhheaa eheah hhhhehehha hea aeaah haheaa he aehehhhhaa eh haeaahhhhh aaaeeahahh hah aheaeeheheh e aha aaeeehe ea hhhaahaeha eaeh h ee ahhehae aaahhhhahhaaa haaeee ea hehhhhhahh hehhea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Consider the numeric expressions in the following sentence from the MedLine Corpus: The corresponding free cortisol fractions in these sera were 4.53 +/- 0.15% and 8.16 +/- 0.23%, respectively.Should we say that the numeric expression 4.53 +/- 0.15% is three words? Or should we say that it's a single compound word? Or should we say that it is actually nine words, since it's read \"four point five three, plus or minus zero point fifteen percent\"? Or should we say that it's not a \"real\" word at all, since it wouldn't appear in any dictionary? Discuss these different possibilities. Can you think of application domains that motivate at least two of these answers?"
      ],
      "metadata": {
        "id": "P343HzfKiCPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ми можемо сказати, що це 3 слова. \n",
        "#Ми можемо сказати, що це 1 слово, але з лінгвістичної точки зору.\n",
        "#Ми не можемо сказати, що це 9 слів, так як дані це числа, а не слова."
      ],
      "metadata": {
        "id": "QR5k8FhpiCpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "◑ Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define μw to be the average number of letters per word, and μs to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: 4.71 μw + 0.5 μs - 21.43. Compute the ARI score for various sections of the Brown Corpus, including section f (lore) and j (learned). Make use of the fact that nltk.corpus.brown.words() produces a sequence of words, whilenltk.corpus.brown.sents() produces a sequence of sentences."
      ],
      "metadata": {
        "id": "LWQqpYE2n3eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sents = nltk.corpus.brown.sents()\n",
        "words = sum(len(s) for s in sents)\n",
        "chars = sum(len(s) for s in sents for w in s)\n",
        "muW = chars / words\n",
        "muS = words / len(sents)\n",
        "ari = 4.71 * muW + 0.5 * muS - 21.43\n",
        "\n",
        "print(ari)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mh-Bq-ln-xd",
        "outputId": "2694a849-0737-4899-fb2d-403817524d8c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124.03363109057847\n"
          ]
        }
      ]
    }
  ]
}